# -*- coding: utf-8 -*-
"""stock_price_predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZDpLdGXq57z2iQ9NvSBiAaTAFPbbTgaK

**Stock price predictor**

This Program uses an Artificial Recurrent Neural Network (RNN) called Long Short Term Meomery(LSTM)
"""

# Importing The Libraries
import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import sequential
from keras.layers import Dense,LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')

pip install --upgrade pandas-datareader

# getting the stock price

df = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2019-12-17')

# display the data
df

df.shape
# no. of rows and columns

# plotting the closing price
# visualising

plt.figure(figsize=(16,8))
plt.title('closing price history')
plt.plot(df['Close'])   # accessing the close column in df above
plt.xlabel('date', fontsize = 18)
plt.ylabel('close price $', fontsize = 18)
plt.show()

# creating a new dataframe with only close column
data = df.filter(['Close'])

# convert the dataframe to numpy array
dataset = data.values

# get no. of rows to train the model on
training_data_len = math.ceil(len(dataset)*0.8)   # means we are blocking about 80% of data for
                                                  # Training our neural network

training_data_len

"""**Scaling data to fit in Neural Network**

"""

# let's scale our data
# neural network takes value only in range [0,1]
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)
# fit_transform() is used for scaling our data and also learn the scaling parameters
# it finds the min and max range and then accordingly scale the data (generally b/w 0 to 1)

scaled_data # all value will be from 0 to 1 now

print(scaled_data.shape)
training_data_len

# create the training data set
# create the scaled training data set

train_data = scaled_data[0:training_data_len, :]    
# getting no of rows from 0 to training data len(1603) and all columns(1)

# split the data into x_train and y_train sets
x_train = []
y_train = []
for i in range(60, len(train_data)):
  x_train.append(train_data[i-60:i, 0])   # x_train will have values from 0 to 59th index( 60 values)
  y_train.append(train_data[i, 0])    # y_train will have values froom 60th index till len(train_data)
  if i<=61:
    print(x_train)
    print()
    print(y_train)
    print()

# on making i<=61 
# it has 2 arrays of x_train i.e. for i=0 and i=1 hence in the
# 2nd pass 1st value is 2nd element of 1st pass(0.01316509, 0.01457063) and in y_train 
# 1st value is last value of 2nd pass (0.13949272)

# this shows us that the model is accounting for prev values(inputs)

# converting to numpy array
x_train, y_train = np.array(x_train), np.array(y_train)

x_train.shape

# reshape the data
# we need to reshape because the LSTM model expects a 3D data (no. of samples, no. of time steps, no. of features) 
# and our data is currently 2D

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

# reshape(reshaping_list , (samples, time steps, features))
# reshape(x_train, (1543, 60, 1))
# 1543 : no. of samples to look at
# 60 : in one loop or go through see 60 samples (step)
# 1 : only 1 feature i.e. close price

x_train.shape

"""**Building the model**"""

from keras.models import Sequential

# build the LSTM model
# adding various layers to neural network
# 50 : no. of neurons , return_sequences = true in first layer since 
# we'll add another layer , so need to use previous layers output

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1))) # input_shape = (60(time step), 1(no.of features))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))  # normal densely connected layer with 25 neurons
model.add(Dense(1))   # 1 neuron only

# A Dense layer feeds all outputs from the previous layer to all its neurons, it is a fully connected layer
# used for outputting a prediction

"""**Compiling the model**"""

# compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

# optimizer is used to improve upon the loss function
# loss function is used to check how well the model performed while training

"""**Training the model**"""

# Train the model
model.fit(x_train, y_train, batch_size = 1, epochs=1)
# epochs : no. of iteration , the entire dataset is passed forward and backward through neural network

"""**preparing for TESTING**"""

# create the testing data set
# create a new array with values scaled from index 1543 to 2003
test_data = scaled_data[training_data_len - 60 :, : ]
# create the data sets for x_test and y_test
x_test = []
y_test = dataset[training_data_len : , :]
for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i, 0])
  
# converting to numpy array
x_test = np.array(x_test)

# reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

"""**Checking the model**"""

# getting the models predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
# inverse transform kind of unscales the data

# get the RMSE
rmse = np.sqrt(np.mean(predictions - y_test)**2)
rmse

# plot the data
train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions'] = predictions

# visualise the data
# plotting the closing price
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('date', fontsize = 18)
plt.ylabel('close price $', fontsize = 18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Trained on', 'original val', 'Predicted val'], loc = 'lower right')
plt.show()

# showing the valid predicted prices
valid

# get the quote
apple_quote = web.DataReader('AAPL', data_source='yahoo', start='2012-01-01', end='2019-12-17')
# create a new dataframe
new_df = apple_quote.filter(['Close'])
# get the closing price for last 60 days and convert it to an array
last_60_days = new_df[-60:].values
# scale the data b/w 0 to 1
last_60_days_scaled = scaler.transform(last_60_days)
# create an empty list
x_test = []
x_test.append(last_60_days_scaled)
x_test = np.array(x_test)
# reshape the data
x_test = np.reshape(x_test,(x_test.shape[0], x_test.shape[1], 1))
# get the prdeicted scaled price
pred_price = model.predict(x_test)
# undo the scaling
pred_price = scaler.inverse_transform(pred_price)
print(pred_price)

apple_quote2 = web.DataReader('AAPL', data_source='yahoo', start='2019-12-18', end='2019-12-18')
print(apple_quote2['Close'])